# Import Gym Dependencies
import pygame
import time
import mazeEscapeGame
from ClassesMazeEscape.LOCATIONS import LOCATIONS
from ClassesMazeEscape.AGENT import AGENT
from ClassesMazeEscape.ENVIRONMENT import ENVIRONMENT

# Importing Helper Libraries
import numpy as np
from Q_learning import qTrain

# Importing Stable-Baselines3 Stuff
from stable_baselines3 import ppo
from stable_baselines3.common.vec_env import dummy_vec_env
from stable_baselines3.common.evaluation import evaluate_policy

# Simulated Environment: 
"""
To escape a 5x5 hex maze, agent starts on one hex, and must avoid obstacles to find the most optimized path to the end
action_space: can move left, right, up, down
"""
class mazeEscape():
    def __init__(self, fieldSize = 8, map = None) -> None:
        self.fieldSize = fieldSize
        self.windowsWidth = mazeEscapeGame.windowsWidth
        self.windowsHeight = mazeEscapeGame.windowsHeight
        self.textAreaHeight = mazeEscapeGame.textAreaHeight
        self.gameDisplay = None

        self.map = map
        if self.map == None:
            locations = LOCATIONS(fieldSize, self.windowsWidth, self.windowsHeight)
            self.map = locations.getMap()
        self.environment = ENVIRONMENT(fieldSize, self.windowsWidth, self.windowsHeight, self.map)
        self.agent = AGENT(fieldSize, self.windowsWidth, self.windowsHeight, self.map)
        self.initialMap = self.map.copy()

        self.state = (self.agent.currentRow, self.agent.currentColumn)
        self.maxSteps = fieldSize*5
        
        self.action_space = Discrete(4) # 4 possible actions: up, down, left, right
        self.observation_space = Tuple((Discrete(fieldSize), Discrete(fieldSize))) # current location on the board

        self.observation_space.high = fieldSize
        self.observation_space.low = 0

    def step(self, action):
        """
        Take an action from the action space and have the RL model apply it to the board
        """
        previousTotalReward = self.agent.totalReward
        self.agent.move(mapAction(action))
        self.state = (self.agent.currentRow, self.agent.currentColumn)
        if self.agent.isCurrentEnd() or self.maxSteps <= 0:
            done = True
        else:
            done = False
        info = {} # for passing additional information if need be
        reward = self.agent.totalReward - previousTotalReward

        self.maxSteps -= 1
        return self.state, reward, done, info

    def render(self, mode = "human"):
        """
        Render and show the current state of the game, where the agent's at and what the current map looks like
        """
        if mode == "human" and self.gameDisplay == None:
            self.gameDisplay = mazeEscapeGame.initializePygame()
        mazeEscapeGame.renderEnvironment(self.gameDisplay, self.environment, self.fieldSize, self.windowsWidth, self.windowsHeight)
        mazeEscapeGame.generateBlankEnvironment(self.gameDisplay, self.fieldSize)
        mazeEscapeGame.putText(self.gameDisplay, "Score:{}".format(self.agent.getScore()), (self.windowsWidth//2, self.windowsHeight+self.textAreaHeight//2))
        pygame.display.update()

    def reset(self):
        """
        Resets the agent to the start and resets the map
        """
        self.maxSteps = self.fieldSize*4
        self.environment.clearEnvironment()
        self.environment.setMap(self.initialMap.copy())
        self.environment.initializeLocations()
        self.agent.setMap(self.environment.getMap())
        self.map = self.environment.getMap()
        self.agent.restartPlayer()
        self.state = (self.agent.currentRow, self.agent.currentColumn)
        return self.state

    def play(self):
        """
        Allows the user to play the game
        """
        mazeEscapeGame.playGame()

# Helper Functions


# myMap = LOCATIONS(6, 1280, 720).getMap()
# myMap = ENVIRONMENT(6, 1280, 720, myMap, False, False).getMap()

# myEnv = mazeEscape(6, myMap)

test = mazeEscape(10)
episodes = 4

qTable = qTrain(test, 10000)

for episode in range(0, episodes):
    state = test.reset()
    done = False
    score = 0
    while not done:
        test.render()
        action = np.argmax(qTable[state])
        state, reward, done, info = test.step(action)
        print("state:{}".format(state))
        time.sleep(0.1)
        score += reward
    print("Episode:{}, Score:{}".format(episode, score))
test.close()
